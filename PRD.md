# **“启智AI”——广东省中小学AI自学辅dǎo助教系统产品需求文档 (PRD)**

## 1. 项目愿景与目标

### 1.1. 项目愿景
打造一个基于AgentScope框架的、符合广东省中小学信息技术课程标准的多智能体AI学习伙伴。该系统旨在通过模拟真实、互动的学习场景，激发学生对人工智能的兴趣，培养其AI素养，并为教师提供创新的教学辅助工具。

### 1.2. 核心目标
- **政策对标**：深度融合《广东省中小学学生人工智能素养框架》与《课程指导纲要》，确保内容与教学目标一致。
- **个性化学习**：通过动态评估和多元化资源，实现“全员普及与个性发展相结合”的理念。
- **思维培养**：不仅传授知识，更注重引导学生的智能思维、计算思维和创新能力。
- **安全可控**：为中小学生提供一个安全、健康、有益的AI互动环境。

---

## 2. 多智能体系统角色设定 (MAS Design)

系统由一个总控管理器和四个核心智能体角色构成，模拟一个围绕“学习者”展开的辅导小组。

### 2.1. 学习者 (User)
- **定义**：学习活动的发起者和核心，是系统的直接使用者（中小学生）。
- **交互方式**：通过自然语言输入文本，提出问题、完成任务、表达观点。
- **核心需求**：获得及时的、个性化的、启发式的学习支持。

### 2.2. 专家智能体 (Expert Agent)
- **角色定位**：课程标准与评估体系的权威化身。
- **核心职责**：
    1.  **动态评估标准制定**：接收学习任务后，依据内置的《素养框架》和《纲要》知识库，生成本次任务的目标和评价维度。可根据学习者历史数据（若有）调整初始难度。
    2.  **学生友好型量规生成**：将专业的考核标准“翻译”成学生易于理解的、可自评的“学习检查单”（Rubrics）。例如：“代码整洁度”会具体化为“变量命名清晰吗？”、“有没有写注释解释你的代码？”等。
    3.  **知识库维护**：作为RAG功能的核心知识源，提供最权威、最准确的回答依据。

### 2.3. 助教智能体 (TA Agent)
- **角色定位**：学习过程的引导者和资源协调者。
- **核心职责**：
    1.  **任务脚手架搭建**：将专家设定的大任务分解为2-3个清晰的子步骤，为“同伴智能体”提供清晰的行动路线图。
    2.  **多元化资源推荐**：根据任务性质，从知识库中检索并推荐文本、视频、在线模拟器（如Scratch、TensorFlow Playground）等多元化学习资源。
    3.  **基于量规的诊断反馈**：在“同伴智能体”完成后，严格对照“专家智能体”生成的量规，逐条进行评价，评价语言正面、有建设性。
    4.  **启发式提问**：在反馈后，提出引导深度思考的问题。例如：“你觉得这个方法在什么情况下会失效？我们能怎么改进它？”

### 2.4. 同伴智能体 (Peer Agent)
- **角色定位**：模拟学习者的“数字孪生”，与学习者共同成长。
- **核心职责**：
    1.  **思考过程外化 (Think Aloud)**：在执行任务时，以第一人称输出“思考过程”，展示如何分析问题、制定策略。
    2.  **模拟常见错误与自我修正**：故意犯一些典型的初学者错误（如逻辑漏洞、语法错误），然后进行自我发现和修正，并解释修正的原因。这能有效降低真实学习者的试错焦虑。
    3.  **榜样示范**：完整地展示一个从接收任务到完成任务的全过程，为学习者提供一个可模仿的范例。

### 2.5. 群聊管理器 (GroupChat Manager)
- **角色定位**：对话流程的导演和主持人。
- **核心职责**：
    1.  **流程控制**：严格按照“专家 -> 助教 -> 同伴 -> 助教”的顺序调度智能体发言。
    2.  **情景转场**：在角色转换时，生成过渡性的总结。例如：“同伴智能体已经为我们展示了解决问题的过程。现在，让我们欢迎助教智能体，看看它会如何评价这份答卷。”
    3.  **用户介入处理**：作为最高优先级监听器，当学习者（用户）在任何时候输入信息时，立即暂停当前流程，将用户输入广播给所有智能体，并引导相关智能体（通常是助教或专家）进行回应，回应后再恢复或重启流程。

---

## 3. 核心功能需求

### 3.1. RAG (检索增强生成)
- **知识库来源**：必须是经过审核的权威资料，包括但不限于《广东省中小学信息技术教材》、《课程指导纲要》、官方推荐的科普文章等。
- **实现方式**：专家智能体和助教智能体在生成内容时，必须优先从该知识库中检索信息，确保知识的准确性和权威性。

### 3.2. 用户随时介入机制
- **实现逻辑**：群聊管理器需要实现一个高优先级的消息监听机制。任何来自用户（learner）的消息都会中断当前的智能体间的对话。管理器将引导合适的智能体（如助教）响应用户的即时需求。

### 3.3. 嵌套聊天 (Agent as a Tool)
- **应用场景**：当助教智能体需要提供一个复杂的代码示例或解释一个专业概念时，它可以临时“召唤”一个专门的“代码生成智能体”或“概念解释智能体”（这些是注册在它内部的工具），在子聊天中完成任务后，将结果返回到主聊天流程中。这可以使每个智能体的职责更单一、更高效。

### 3.4. 未来能力：多模态
- **初步规划**：在V2.0版本中，系统将支持图片输入。例如，学生可以上传一张流程图的照片，让智能体进行分析和评价。同伴智能体在执行任务时，也可以生成简单的图表（如SVG格式）来辅助说明。

---

## 4. 技术架构与部署

### 4.1. 核心框架
- **AgentScope**: v0.1.6或更高版本，利用其多智能体通信（msghub）、工具调用、分布式等特性。

### 4.2. LLM 对接
- **模型**：`kimi-k2-0711-preview` 或其他Kimi系列模型。
- **接入点**：`https://api.moonshot.cn/v1`
- **认证**：API Key严格通过环境变量 `MOONSHOT_API_KEY` 读取。

### 4.3. 后端服务与部署
- **服务封装**：整个多智能体应用将被封装成一个FastAPI服务。
- **接口设计**：提供清晰的HTTP接口（如 `/chat`），接收来自Web前端（通过Spring Boot后端转发）的请求，并以流式（Streaming）或JSON格式返回对话结果。
- **部署**：未来考虑使用Docker进行容器化部署，方便管理和扩展。

### 4.4. 可视化与监控
- **AgentScope Studio**：开发阶段将连接到本地的AgentScope Studio (`http://localhost:3000`)，用于监控Token使用、调试智能体交互流程。

---

## 5. 优化与创意功能 (V1.1+)

- **学习档案**：为每个学生（基于匿名ID）建立简单的学习档案，记录其交互历史和任务完成情况，用于“专家智能体”进行更精准的动态难度调整。
- **“灵感火花”功能**：当学生与系统讨论某个知识点时，助教智能体可以主动推荐一个相关的、小型的、可以立即动手的创意项目，激发学生的创造力。
- **教师观察模式**：未来可开发一个教师端界面，教师可以“静默”地观察学生的学习过程，并查看系统的评估和反馈，作为教学参考。

---

请您审阅以上PRD。如果确认无误，我将开始着手进行项目的初始化和代码结构搭建。